{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "import yaml\n",
    "import datetime\n",
    "import pytesseract as ocr\n",
    "from PIL import Image\n",
    "from src import pre_process as pp\n",
    "import os\n",
    "\n",
    "# configurations to read from YAML file\n",
    "configs = None\n",
    "def read_configs(config_file):\n",
    "    \"\"\" .yml file 을 읽어서 configuration 값의 객체를 갖습니다.\n",
    "    :param config_file:\n",
    "    :return: 읽은 configuration 을 담고있는 dictionary 형태로 반환\n",
    "    \"\"\"\n",
    "    # read contents from .yam config file\n",
    "    with open(config_file, 'r') as yml_file:\n",
    "        configurations = yaml.load(yml_file)  # use 'yaml' package to read .yml file\n",
    "\n",
    "    global configs  # global var : configs\n",
    "    configs = configurations  # set configs\n",
    "    return configurations  # return read configurations\n",
    "\n",
    "read_configs('C:/Users/Purple/textrecognition/config.yml')\n",
    "\n",
    "def recognize_text_from_file(image_path):\n",
    "    model_full_path = 'C:/Users/Purple/textrecognition/model/learning_graph.pb'\n",
    "    labels_full_path = 'C:/Users/Purple/textrecognition/model/learning_labels.txt'\n",
    "    # Read in the image_data\n",
    "    image_data = tf.gfile.FastGFile(image_path, 'rb').read()\n",
    "\n",
    "    # Loads label file, strips off carriage return\n",
    "    label_lines = [line.rstrip() for line\n",
    "                   in tf.gfile.GFile(labels_full_path)]\n",
    "\n",
    "    # Unpersists graph from file\n",
    "    with tf.gfile.FastGFile(model_full_path, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "    \n",
    "    # Unpersists graph from file\n",
    "    with tf.Session() as sess:\n",
    "        # Feed the image_data as input to the graph and get first prediction\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "        predictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': image_data})\n",
    "\n",
    "        # Sort to show labels of first prediction in order of confidence\n",
    "        top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
    "    # get most likely classification\n",
    "    answer = label_lines[top_k[0]]\n",
    "    return answer\n",
    "\n",
    "def get_language_from_file(image_path):\n",
    "    model_full_path = 'C:/Users/Purple/textrecognition/workspace/language_graph.pb'\n",
    "    labels_full_path = 'C:/Users/Purple/textrecognition/workspace/language_labels.txt'\n",
    "    # Read in the image_data\n",
    "    image_data = tf.gfile.FastGFile(image_path, 'rb').read()\n",
    "\n",
    "    # Loads label file, strips off carriage return\n",
    "    label_lines = [line.rstrip() for line\n",
    "                   in tf.gfile.GFile(labels_full_path)]\n",
    "\n",
    "    # Unpersists graph from file\n",
    "    with tf.gfile.FastGFile(model_full_path, 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        _ = tf.import_graph_def(graph_def, name='')\n",
    "    \n",
    "    # Unpersists graph from file\n",
    "    with tf.Session() as sess:\n",
    "        # Feed the image_data as input to the graph and get first prediction\n",
    "        softmax_tensor = sess.graph.get_tensor_by_name('final_result:0')\n",
    "        predictions = sess.run(softmax_tensor, {'DecodeJpeg/contents:0': image_data})\n",
    "\n",
    "        # Sort to show labels of first prediction in order of confidence\n",
    "        top_k = predictions[0].argsort()[-len(predictions[0]):][::-1]\n",
    "    language = label_lines[top_k[0]]\n",
    "    return language\n",
    "\n",
    "def get_origin_text_from_file(image):\n",
    "    \"\"\" OCR 엔진(tesseract) 를 이용해 이미지에서 글자를 추출합니다.\n",
    "    :param image: 텍스트(Text)를 추출할 resource 이미지\n",
    "    :return: 추출한 텍스트(Text)를 String 형으로 반환\n",
    "    \"\"\"\n",
    "    # todo language 도 configs.yml file 에서 설정할 수 있도록 변경하기\n",
    "    img = Image.open(open(image,'rb'))\n",
    "    text = ocr.image_to_string(img, lang='eng+chi')\n",
    "    return text\n",
    "\n",
    "def get_text_from_file(image):\n",
    "    \"\"\" OCR 엔진(tesseract) 를 이용해 이미지에서 글자를 추출합니다.\n",
    "    :param image: 텍스트(Text)를 추출할 resource 이미지\n",
    "    :return: 추출한 텍스트(Text)를 String 형으로 반환\n",
    "    \"\"\"\n",
    "    # todo language 도 configs.yml file 에서 설정할 수 있도록 변경하기\n",
    "    img = Image.open(open(image, 'rb'))\n",
    "    text =[]\n",
    "    if recognize_text_from_file(image) == 'text' :\n",
    "        text = ocr.image_to_string(img, lang='eng+chi_sim')\n",
    "    return text\n",
    "    \n",
    "    \n",
    "def get_textlanguage_from_file(image):\n",
    "    \"\"\" OCR 엔진(tesseract) 를 이용해 이미지에서 글자를 추출합니다.\n",
    "    :param image: 텍스트(Text)를 추출할 resource 이미지\n",
    "    :return: 추출한 텍스트(Text)를 String 형으로 반환\n",
    "    \"\"\"\n",
    "    # todo language 도 configs.yml file 에서 설정할 수 있도록 변경하기\n",
    "    img = Image.open(open(image, 'rb'))\n",
    "    text=[]\n",
    "    if recognize_text_from_file(image) == 'text' :\n",
    "        if get_language_from_file(image) == 'eng' :\n",
    "            text = ocr.image_to_string(img, lang='eng')\n",
    "        elif get_language_from_file(image) == 'chi' :\n",
    "            text = ocr.image_to_string(img, lang='chi')\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import pre_process as pp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def show_window(image, title='untitled', max_height=700):\n",
    "    \"\"\" 이미지 윈도우를 열어서 보여줍니다.\n",
    "\n",
    "    :param image: 보여줄 이미지 (OpenCV image 객체)\n",
    "    :param title: 윈도우 제목\n",
    "    :param max_height: 이미지 윈도우 사이즈의 최대 높이\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    height, width = image.shape[:2]  # get image size\n",
    "    if height > max_height:  # adjust window size if too large\n",
    "        rate = max_height / height\n",
    "        height = round(height * rate)\n",
    "        width = round(width * rate)  # apply the same rate to width\n",
    "\n",
    "    cv2.namedWindow(title, cv2.WINDOW_NORMAL)  # Create a window that the user can resize\n",
    "    cv2.resizeWindow(title, width, height)  # resize window according to the size of the image\n",
    "    cv2.imshow(title, image)  # open image window\n",
    "    key = cv2.waitKey(0)  # wait until keyboard input\n",
    "    cv2.destroyAllWindows()\n",
    "    return key\n",
    "\n",
    "\n",
    "def merge_horizontal(image_gray, image_bgr):\n",
    "    \"\"\" Height 사이즈가 같은 두 이미지를 옆으로(Horizontally) 병합 합니다.\n",
    "    이미지 처리(Image processing) 단계를 원본과 비교하기위한 목적으로,\n",
    "    2차원(2 dimension) 흑백 이미지와 3차원(3 dimension) BGR 컬리 이미지를 인자로 받아 병합합니다.\n",
    "\n",
    "    :param image_gray: 2차원(2 dimension) 흑백 이미지\n",
    "    :param image_bgr: 3차원(3 dimension) BGR 컬리 이미지\n",
    "    :return: 옆으로(Horizontally) 병합된 이미지\n",
    "    \"\"\"\n",
    "    # Make the grey scale image have 3 channels\n",
    "    image_cr = cv2.cvtColor(image_gray, cv2.COLOR_GRAY2BGR)\n",
    "    # Merge image horizontally\n",
    "    numpy_horizontal = np.hstack((image_cr, image_bgr))\n",
    "    # numpy_horizontal_concat = np.concatenate((image, image_contours), axis=1)\n",
    "    return numpy_horizontal\n",
    "\n",
    "\n",
    "def merge_vertical(image_gray, image_bgr):\n",
    "    \"\"\" Width 사이즈가 같은 두 이미지를 위아래로(Vertically) 병합 합니다.\n",
    "    이미지 처리(Image processing) 단계를 원본과 비교하기위한 목적으로,\n",
    "    2차원(2 dimension) 흑백 이미지와 3차원(3 dimension) BGR 컬리 이미지를 인자로 받아 병합합니다.\n",
    "\n",
    "    :param image_gray: 2차원(2 dimension) 흑백 이미지\n",
    "    :param image_bgr: 3차원(3 dimension) BGR 컬리 이미지\n",
    "    :return: 위아래로(Vertically) 병합된 이미지\n",
    "    \"\"\"\n",
    "    # Make the grey scale image have 3 channels\n",
    "    image_cr = cv2.cvtColor(image_gray, cv2.COLOR_GRAY2BGR)\n",
    "    # Merge image horizontally\n",
    "    numpy_vertical = np.vstack((image_cr, image_bgr))\n",
    "    return numpy_vertical\n",
    "\n",
    "\n",
    "def detect_line(image_binary):\n",
    "    \"\"\" 이미지에서 직선을 찾아서 초록색으로 표시한 결과를 반환합니다.\n",
    "\n",
    "    :param image_binary: 흑백(Binary) OpenCV image (2 dimension)\n",
    "    :return: 라인이 삭제된 이미지 (OpenCV image)\n",
    "    \"\"\"\n",
    "    copy = image_binary.copy()  # copy the image to be processed\n",
    "    copy_rbg = cv2.cvtColor(copy, cv2.COLOR_GRAY2RGB)\n",
    "    # get configs\n",
    "    threshold = pp.configs['remove_line']['threshold']\n",
    "    min_line_length = pp.configs['remove_line']['min_line_length']\n",
    "    max_line_gap = pp.configs['remove_line']['max_line_gap']\n",
    "\n",
    "    # fine and draw lines\n",
    "    lines = cv2.HoughLinesP(copy, 1, np.pi / 180, threshold, np.array([]), min_line_length, max_line_gap)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]  # get end point of line : ( (x1, y1) , (x2, y2) )\n",
    "            # slop = 0\n",
    "            # if x2 != x1:\n",
    "            #     slop = abs((y2-y1) / (x2-x1))\n",
    "            # if slop < 0.5 or slop > 50 or x2 == x1:  # only vertical or parallel lines.\n",
    "            #  remove line drawing black line\n",
    "            cv2.line(copy_rbg, (x1, y1), (x2, y2), (0, 155, 0), 2)\n",
    "    return copy_rbg\n",
    "\n",
    "\n",
    "def get_step_compare_image(path_of_image):\n",
    "    \"\"\" 이미지 프로세싱 전 단계의 중간 결과물을 하나로 병합하여 반환합니다.\n",
    "\n",
    "    :param path_of_image:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # open original image\n",
    "    image_origin = pp.open_original(path_of_image)\n",
    "    # size up ( x4 )\n",
    "    image_origin = cv2.pyrUp(image_origin)\n",
    "    comparing_images = []\n",
    "\n",
    "    # Grey-Scale\n",
    "    image_gray = pp.get_gray(image_origin)\n",
    "    contours = pp.get_contours(image_gray)\n",
    "    image_with_contours = pp.draw_contour_rect(image_origin, contours)\n",
    "    # merge two image vertically\n",
    "    compare_set = merge_vertical(image_gray, image_with_contours)\n",
    "    comparing_images.append(compare_set)\n",
    "\n",
    "    # Morph Gradient\n",
    "    image_gradient = pp.get_gradient(image_gray)\n",
    "    # image_gradient = pp.get_canny(image_gray)\n",
    "    contours = pp.get_contours(image_gradient)\n",
    "    image_with_contours = pp.draw_contour_rect(image_origin, contours)\n",
    "    # merge two current step image vertically\n",
    "    compare_set = merge_vertical(image_gradient, image_with_contours)\n",
    "    comparing_images.append(compare_set)\n",
    "\n",
    "    # Threshold\n",
    "    image_threshold = pp.get_threshold(image_gradient)\n",
    "    contours = pp.get_contours(image_threshold)\n",
    "    image_with_contours = pp.draw_contour_rect(image_origin, contours)\n",
    "    # merge two image vertically\n",
    "    compare_set = merge_vertical(image_threshold, image_with_contours)\n",
    "    comparing_images.append(compare_set)\n",
    "    \n",
    "    # Morph Close\n",
    "    image_close = pp.get_closing(image_threshold)\n",
    "    contours = pp.get_contours(image_close)\n",
    "    image_with_contours = pp.draw_contour_rect(image_origin, contours)\n",
    "    # merge two image vertically\n",
    "    compare_set = merge_vertical(image_close, image_with_contours)\n",
    "    comparing_images.append(compare_set)\n",
    "\n",
    "    # Long line remove\n",
    "    image_line_removed = pp.remove_long_line(image_close)\n",
    "    contours = pp.get_contours(image_line_removed)\n",
    "    image_with_contours = pp.draw_contour_rect(image_origin, contours)\n",
    "    \n",
    "    # merge two image vertically\n",
    "    compare_set = merge_vertical(image_line_removed, image_with_contours)\n",
    "    comparing_images.append(compare_set)\n",
    "\n",
    "\n",
    "    # Merge all step's images horizontally\n",
    "    image_merged_all = np.hstack(comparing_images)\n",
    "\n",
    "    return image_merged_all\n",
    "\n",
    "\n",
    "def get_image_with_contours(path_of_image):\n",
    "    \"\"\" 이미지 프로세싱을 거친 후,\n",
    "    최종적으로 얻은 Contours 를 원본 이미지 위에 그려서 반환합니다.\n",
    "\n",
    "    :param path_of_image:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # open original image\n",
    "    image_origin = pp.open_original(path_of_image)\n",
    "    # size up the resource ( x4 )\n",
    "    image_origin = cv2.pyrUp(image_origin)\n",
    "    # Grey-Scale\n",
    "    image_gray = pp.get_gray(image_origin)\n",
    "    # Morph Gradient\n",
    "    image_gradient = pp.get_gradient(image_gray)\n",
    "    # Threshold\n",
    "    image_threshold = pp.get_threshold(image_gradient)\n",
    "    # Long line remove\n",
    "    image_line_removed = pp.remove_long_line(image_threshold)\n",
    "    # Morph Close\n",
    "    image_close = pp.get_closing(image_line_removed)\n",
    "    # Get contours and Draw it on the original image\n",
    "    contours = pp.get_contours(image_close)\n",
    "    image_with_contours = pp.draw_contour_rect(image_origin, contours)\n",
    "    return image_with_contours\n",
    "\n",
    "\n",
    "def get_file_list(path):\n",
    "    \"\"\" path 가 가리키는 directory 의 모든 파일명을 읽어서 string 으로 반환합니다.\n",
    "    파일명은 Absolute path 가 포함된 이름입니다.\n",
    "\n",
    "    :param path: 읽어 들일 directory 의 절대경로\n",
    "    :return: directory 의 모든 file path 을 String 형으로 Array 에 담아 반환\n",
    "    \"\"\"\n",
    "    image_path_list = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        root_path = os.path.join(os.path.abspath(path), root)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root_path, file)\n",
    "            image_path_list.append(file_path)\n",
    "\n",
    "    return image_path_list\n",
    "\n",
    "\n",
    "\n",
    "    return messages\n",
    "\n",
    "def get_image_with_lines(image_path):\n",
    "    image_origin = pp.open_original(image_path)\n",
    "    image_origin = cv2.pyrUp(image_origin)\n",
    "    # Grey-Scale\n",
    "    image_gray = pp.get_gray(image_origin)\n",
    "    # Morph Gradient\n",
    "    image_gradient = pp.get_gradient(image_gray)\n",
    "    # Threshold\n",
    "    image_threshold = pp.get_threshold(image_gradient)\n",
    "    # find and draw lines\n",
    "    image_line_removed = detect_line(image_threshold)\n",
    "    return image_line_removed\n",
    "\n",
    "def read_configs(config_file):\n",
    "    \"\"\" .yml file 을 읽어서 configuration 값의 객체를 갖습니다.\n",
    "\n",
    "    :param config_file:\n",
    "    :return: 읽은 configuration 을 담고있는 dictionary 형태로 반환\n",
    "    \"\"\"\n",
    "    # read contents from .yam config file\n",
    "    with open(config_file, 'r') as yml_file:\n",
    "        configurations = yaml.load(yml_file)  # use 'yaml' package to read .yml file\n",
    "\n",
    "    global configs  # global var : configs\n",
    "    configs = configurations  # set configs\n",
    "    return configurations  # return read configurations\n",
    "\n",
    "\n",
    "def print_configs():\n",
    "    \"\"\" 전역변수 configs 에 저장된 configuration 내용을 출력합니다.\n",
    "\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    global configs  # refer global variable : configs\n",
    "    for section in configs:\n",
    "        print(section + \":\")\n",
    "        print(configs[section])\n",
    "\n",
    "\n",
    "def resize(image, flag=-1):\n",
    "    \"\"\" Configuration 의 width, height 값을 기준으로 이미지 사이즈를 변경합니다.\n",
    "\n",
    "    :param image - cv2 이미지 객체\n",
    "    :param flag - flag > 0 이면 사이즈를 증가, flag < 0 (default)이면 사이즈를 축소\n",
    "    :return: image_copy - 사이즈가 변환된 이미지\n",
    "    \"\"\"\n",
    "    # get configs\n",
    "    global configs\n",
    "    standard_height = configs['resize_origin']['standard_height']\n",
    "    standard_width = configs['resize_origin']['standard_width']\n",
    "    # get image size\n",
    "    height, width = image.shape[:2]\n",
    "    image_copy = image.copy()\n",
    "    # print original size (width, height)\n",
    "    print(\"origin (width : \" + str(width) + \", height : \" + str(height) + \")\")\n",
    "    rate = 1  # default\n",
    "    if (flag > 0 and height < standard_height) or (flag < 0 and height > standard_height):  # Resize based on height\n",
    "        rate = standard_height / height\n",
    "    elif (flag > 0 and width < standard_width) or (flag < 0 and height > standard_height):  # Resize based on width\n",
    "        rate = standard_width / width\n",
    "    # resize\n",
    "    w = round(width * rate)  # should be integer\n",
    "    h = round(height * rate)  # should be integer\n",
    "    image_copy = cv2.resize(image_copy, (w, h))\n",
    "    # print modified size (width, height)\n",
    "    print(\"after resize : (width : \" + str(w) + \", height : \" + str(h) + \")\")\n",
    "    return image_copy\n",
    "\n",
    "\n",
    "def open_original(file_path):\n",
    "    \"\"\" image file 을 읽어들여서 OpenCV image 객체로 반환합니다.\n",
    "\n",
    "    :param file_path:  경로를 포함한 이미지 파일\n",
    "    :return:  OpenCV 의 BGR image 객체 (3 dimension)\n",
    "    \"\"\"\n",
    "    image_origin = cv2.imread(file_path)  # read image from file\n",
    "    return image_origin\n",
    "\n",
    "\n",
    "def get_gray(image_origin):\n",
    "    \"\"\" image 객체를 인자로 받아서 Gray-scale 을 적용한 2차원 이미지 객체로 반환합니다.\n",
    "    이 때 인자로 입력되는 이미지는 BGR 컬러 이미지여야 합니다.\n",
    "\n",
    "    :param image_origin: OpenCV 의 BGR image 객체 (3 dimension)\n",
    "    :return: gray-scale 이 적용된 image 객체 (2 dimension)\n",
    "    \"\"\"\n",
    "    copy = image_origin.copy()  # copy the image to be processed\n",
    "    image_grey = cv2.cvtColor(copy, cv2.COLOR_BGR2GRAY)  # apply gray-scale to the image\n",
    "    return image_grey\n",
    "\n",
    "\n",
    "def get_canny(image_gray):\n",
    "    copy = image_gray.copy()\n",
    "    kernel_size = 5\n",
    "    blur_gray = cv2.GaussianBlur(copy, (kernel_size, kernel_size), 0)\n",
    "    low_threshold = 50\n",
    "    high_threshold = 150\n",
    "    edges = cv2.Canny(blur_gray, low_threshold, high_threshold)\n",
    "    return edges\n",
    "\n",
    "\n",
    "def get_gradient(image_gray):\n",
    "    \"\"\" 이미지에 Dilation 과 Erosion 을 적용하여 그 차이를 이용해 윤곽선을 추출합니다.\n",
    "    이 때 인자로 입력되는 이미지는 Gray scale 이 적용된 2차원 이미지여야 합니다.\n",
    "\n",
    "    :param image_gray: Gray-scale 이 적용된 OpenCV image (2 dimension)\n",
    "    :return: 윤곽선을 추출한 결과 이미지 (OpenCV image)\n",
    "    \"\"\"\n",
    "    copy = image_gray.copy()  # copy the image to be processed\n",
    "    # get configs\n",
    "    global configs\n",
    "    kernel_size_row = configs['gradient']['kernel_size_row']\n",
    "    kernel_size_col = configs['gradient']['kernel_size_col']\n",
    "    # make kernel matrix for dilation and erosion\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (kernel_size_row, kernel_size_col))\n",
    "    # morph gradient\n",
    "    image_gradient = cv2.morphologyEx(copy, cv2.MORPH_GRADIENT, kernel)\n",
    "    return image_gradient\n",
    "\n",
    "\n",
    "def remove_long_line(image_binary):\n",
    "    \"\"\" 이미지에서 직선을 찾아서 삭제합니다.\n",
    "    글자 경계를 찾을 때 방해가 되는 직선을 찾아서 삭제합니다.\n",
    "    이 때 인자로 입력되는 이미지 2 차원(2 dimension) 흑백(Binary) 이미지여야 합니다.\n",
    "    직선을 삭제할 때는 해당 라인을 검정색으로 그려 덮어 씌웁니다. \n",
    "\n",
    "    :param image_binary: 흑백(Binary) OpenCV image (2 dimension)\n",
    "    :return: 라인이 삭제된 이미지 (OpenCV image)\n",
    "    \"\"\"\n",
    "    copy = image_binary.copy()  # copy the image to be processed\n",
    "    # get configs\n",
    "    global configs\n",
    "    threshold = configs['remove_line']['threshold']\n",
    "    min_line_length = configs['remove_line']['min_line_length']\n",
    "    max_line_gap = configs['remove_line']['max_line_gap']\n",
    "\n",
    "    # find and remove lines\n",
    "    lines = cv2.HoughLinesP(copy, 1, np.pi / 180, threshold, np.array([]), min_line_length, max_line_gap)\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            x1, y1, x2, y2 = line[0]  # get end point of line : ( (x1, y1) , (x2, y2) )\n",
    "            slop = 0\n",
    "            if x2 != x1:\n",
    "                slop = abs((y2-y1) / (x2-x1))\n",
    "                if slop > 50 or x2 == x1 :  # only vertical or parallel lines.\n",
    "                    cv2.line(copy, (x1, y1), (x2, y2), (0, 0, 0), 2)\n",
    "    return copy\n",
    "\n",
    "\n",
    "def get_threshold(image_gray):\n",
    "    \"\"\" 이미지에 Threshold 를 적용해서 흑백(Binary) 이미지객체를 반환합니다.\n",
    "    이 때 인자로 입력되는 이미지는 Gray-scale 이 적용된 2차원 이미지여야 합니다.\n",
    "    configs 에 적용된 threshold mode 에 따라 global threshold / mean adaptive threshold / gaussian adaptive threshold\n",
    "    를 적용할 수 있습니다.\n",
    "\n",
    "    :param image_gray: Gray-scale 이 적용된 OpenCV image (2 dimension)\n",
    "    :return: Threshold 를 적용한 흑백(Binary) 이미지\n",
    "    \"\"\"\n",
    "    copy = image_gray.copy()  # copy the image to be processed\n",
    "    # get configs\n",
    "    global configs\n",
    "    mode = configs['threshold']['mode']  # get threshold mode (mean or gaussian or global)\n",
    "    block_size = configs['threshold']['block_size']\n",
    "    subtract_val = configs['threshold']['subtract_val']\n",
    "\n",
    "    if mode == 'mean':  # adaptive threshold - mean\n",
    "        image_threshold = cv2.adaptiveThreshold(copy, 255, cv2.ADAPTIVE_THRESH_MEAN_C,\n",
    "                                                cv2.THRESH_BINARY_INV, block_size, subtract_val)\n",
    "    elif mode == 'gaussian':  # adaptive threshold - gaussian\n",
    "        image_threshold = cv2.adaptiveThreshold(copy, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                                cv2.THRESH_BINARY_INV, block_size, subtract_val)\n",
    "    else:  # (mode == 'global') global threshold - otsu's binary operation\n",
    "        image_threshold = get_otsu_threshold(copy)\n",
    "\n",
    "    return image_threshold  # Returns the image with the threshold applied.\n",
    "\n",
    "\n",
    "def get_global_threshold(image_gray, threshold_value=130):\n",
    "    \"\"\" 이미지에 Global Threshold 를 적용해서 흑백(Binary) 이미지객체를 반환합니다.\n",
    "    하나의 값(threshold_value)을 기준으로 이미지 전체에 적용하여 Threshold 를 적용합니다.\n",
    "    픽셀의 밝기 값이 기준 값 이상이면 흰색, 기준 값 이하이면 검정색을 적용합니다.\n",
    "    이 때 인자로 입력되는 이미지는 Gray-scale 이 적용된 2차원 이미지여야 합니다.\n",
    "    \n",
    "    :param image_gray:\n",
    "    :param threshold_value: 이미지 전체에 Threshold 를 적용할 기준 값.\n",
    "    :return: Global Threshold 를 적용한 흑백(Binary) 이미지\n",
    "    \"\"\"\n",
    "    copy = image_gray.copy()  # copy the image to be processed\n",
    "    _, binary_image = cv2.threshold(copy, threshold_value, 255, cv2.THRESH_BINARY)\n",
    "    return binary_image\n",
    "\n",
    "\n",
    "def get_otsu_threshold(image_gray):\n",
    "    \"\"\"  이미지에 Global Threshold 를 적용해서 흑백(Binary) 이미지객체를 반환합니다.\n",
    "    하나의 값을 기준으로 이미지 전체에 적용하여 Threshold 를 적용합니다.\n",
    "    해당 값은 Otsu's Binarization 에 의해 자동으로 이미지의 히스토그램을 분석한 후 중간값으로 설정됩니다.\n",
    "    픽셀의 밝기 값이 기준 값 이상이면 흰색, 기준 값 이하이면 검정색을 적용합니다.\n",
    "    이 때 인자로 입력되는 이미지는 Gray-scale 이 적용된 2차원 이미지여야 합니다.\n",
    "\n",
    "    :param image_gray: Gray-scale 이 적용된 OpenCV image (2 dimension)\n",
    "    :return: Otsu's Binarization에 의해 Global Threshold 를 적용한 흑백(Binary) 이미지\n",
    "    \"\"\"\n",
    "    copy = image_gray.copy()  # copy the image to be processed\n",
    "    blur = cv2.GaussianBlur(copy, (5, 5), 0)  # Gaussian blur 를 통해 noise 를 제거한 후\n",
    "    # global threshold with otsu's binarization\n",
    "    ret3, image_otsu = cv2.threshold(copy, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    return image_otsu\n",
    "\n",
    "\n",
    "def get_closing(image_gray):\n",
    "    \"\"\" 이미지에 Morph Close 를 적용한 이미지객체를 반환합니다.\n",
    "    이미지에 Dilation 수행을 한 후 Erosion 을 수행한 것입니다.\n",
    "    이 때 인자로 입력되는 이미지는 Gray-scale 이 적용된 2차원 이미지여야 합니다.\n",
    "    configs 에 의해 kernel size 값을 설정할 수 있습니다.\n",
    "\n",
    "    :param image_gray: Gray-scale 이 적용된 OpenCV image (2 dimension)\n",
    "    :return: Morph Close 를 적용한 흑백(Binary) 이미지\n",
    "    \"\"\"\n",
    "    copy = image_gray.copy()  # copy the image to be processed\n",
    "    # get configs\n",
    "    global configs\n",
    "    kernel_size_row = configs['close']['kernel_size_row']\n",
    "    kernel_size_col = configs['close']['kernel_size_col']\n",
    "    # make kernel matrix for dilation and erosion\n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (kernel_size_row, kernel_size_col))\n",
    "    # closing (dilation and erosion)\n",
    "    image_close = cv2.morphologyEx(copy, cv2.MORPH_CLOSE, kernel)\n",
    "    return image_close\n",
    "\n",
    "\n",
    "def get_contours(image):\n",
    "    \"\"\" 이미지에서 Contour 를 추출하여 반환합니다.\n",
    "    Contour 추출 모드는 configs 에서 설정할 수 있습니다.\n",
    "    찾은 contour 리스트를 dictionary 형태로 반환합니다.\n",
    "    이미지 처리(Image processing) 단계를 거친 후 contour 를 잘 추출할 수 있습니다.\n",
    "\n",
    "    :param image: OpenCV의 image 객체 (2 dimension)\n",
    "    :return: 이미지에서 추출한 contours\n",
    "    \"\"\"\n",
    "    # get configs\n",
    "    global configs\n",
    "    retrieve_mode = configs['contour']['retrieve_mode']  # integer value\n",
    "    approx_method = configs['contour']['approx_method']  # integer value\n",
    "    # find contours from the image\n",
    "    _, contours, _ = cv2.findContours(image, retrieve_mode, approx_method)\n",
    "    return contours\n",
    "\n",
    "\n",
    "def draw_contour_rect(image_origin, contours):\n",
    "    \"\"\" 사각형의 Contour 를 이미지 위에 그려서 반환합니다.\n",
    "    찾은 Contours 를 기반으로 이미지 위에 각 contour 를 감싸는 외각 사각형을 그립니다.\n",
    "\n",
    "    :param image_origin: OpenCV의 image 객체\n",
    "    :param contours: 이미지 위에 그릴 contour 리스트\n",
    "    :return: 사각형의 Contour 를 그린 이미지\n",
    "    \"\"\"\n",
    "    rgb_copy = image_origin.copy()  # copy the image to be processed\n",
    "    # get configs\n",
    "    global configs\n",
    "    min_width = configs['contour']['min_width']\n",
    "    min_height = configs['contour']['min_height']\n",
    "    # Draw bounding rectangles\n",
    "    for contour in contours:\n",
    "        x, y, width, height = cv2.boundingRect(contour)  # top-left vertex coordinates (x,y) , width, height\n",
    "        # Draw screenshot that are larger than the standard size\n",
    "        if width > min_width and height > min_height:\n",
    "            cv2.rectangle(rgb_copy, (x, y), (x + width, y + height), (0, 255, 0), 2)\n",
    "\n",
    "    return rgb_copy\n",
    "\n",
    "def get_cropped_images(image_origin, contours):\n",
    "    \"\"\" 이미지에서 찾은 Contour 부분들을 잘라내어 반환합니다.\n",
    "    각 contour 를 감싸는 외각 사각형에 여유분(padding)을 주어 이미지를 잘라냅니다.\n",
    "\n",
    "    :param image_origin: 원본 이미지\n",
    "    :param contours: 잘라낼 contour 리스트\n",
    "    :return: contours 를 기반으로 잘라낸 이미지(OpenCV image 객체) 리스트\n",
    "    \"\"\"\n",
    "    image_copy = image_origin.copy()  # copy the image to be processed\n",
    "    # get configs\n",
    "    global configs\n",
    "    min_width = configs['contour']['min_width']\n",
    "    min_height = configs['contour']['min_height']\n",
    "    padding = 10  # to give the padding when cropping the screenshot\n",
    "    origin_height, origin_width = image_copy.shape[:2]  # get image size\n",
    "    cropped_images = []  # list to save the crop image.\n",
    "\n",
    "    for contour in contours:  # Crop the screenshot with on bounding rectangles of contours\n",
    "        x, y, width, height = cv2.boundingRect(contour)  # top-left vertex coordinates (x,y) , width, height\n",
    "        # screenshot that are larger than the standard size\n",
    "        if width > min_width and height > min_height:\n",
    "            # The range of row to crop (with padding)\n",
    "            row_from = (y - padding) if (y - padding) > 0 else y\n",
    "            row_to = (y + height + padding) if (y + height + padding) < origin_height else y + height\n",
    "            # The range of column to crop (with padding)\n",
    "            col_from = (x - padding) if (x - padding) > 0 else x\n",
    "            col_to = (x + width + padding) if (x + width + padding) < origin_width else x + width\n",
    "            # Crop the image with Numpy Array\n",
    "            cropped = image_copy[row_from: row_to, col_from: col_to]\n",
    "            cropped_images.append(cropped)  # add to the list\n",
    "    return cropped_images\n",
    "\n",
    "\n",
    "\n",
    "def get_text_from_image(image):\n",
    "    \"\"\" OCR 엔진(tesseract) 를 이용해 이미지에서 글자를 추출합니다.\n",
    "\n",
    "    :param image: 텍스트(Text)를 추출할 resource 이미지\n",
    "    :return: 추출한 텍스트(Text)를 String 형으로 반환\n",
    "    \"\"\"\n",
    "    # todo language 도 configs.yml file 에서 설정할 수 있도록 변경하기\n",
    "    img = Image.open(open(image,'rb'))\n",
    "    text = ocr.image_to_string(img, lang='eng+chi')\n",
    "    return text\n",
    "\n",
    "def process_image(image_file):\n",
    "    \"\"\" 다섯 단계의 이미지 처리(Image precessing)를 힙니다.\n",
    "    현재 함수에서 순서를 변경하여 적용할 수 있습니다.\n",
    "    1) Gray-scale 적용\n",
    "    2) Morph Gradient 적용\n",
    "    3) Threshold 적용\n",
    "    4) Long Line Removal 적용\n",
    "    5) Close 적용\n",
    "    6) Contour 추출\n",
    "\n",
    "    :param image_file: 이미지 처리(Image precessing)를 적용할 이미지 파일\n",
    "    :return: 이미지 처리 후 글자로 추정되는 부분을 잘라낸 이미지 리스트\n",
    "    \"\"\"\n",
    "    image_origin = open_original(image_file)\n",
    "    # todo input 사이즈가 일정 수준 이하일 경우 cv2.pyrUp() 으로 사이즈를 확장할 수 있도록 자동화하기\n",
    "    # todo 아니면 설정파일에서 사이즈업 할지말지를 선택할 수 있도록 하기 (configs.yml)\n",
    "    # image_origin = cv2.pyrUp(image_origin)  # size up ( x4 )  이미지 크기가 작을 경우 이미지 사이즈업 해야합니다.\n",
    "    # Grey-Scale\n",
    "    image_gray = get_gray(image_origin)\n",
    "    # Morph Gradient\n",
    "    image_gradient = get_gradient(image_gray)\n",
    "    # Threshold\n",
    "    image_threshold = get_threshold(image_gradient)\n",
    "    # Morph Close\n",
    "    image_close = get_closing(image_threshold)\n",
    "    # Long line remove\n",
    "    image_line_removed = remove_long_line(image_close)\n",
    "\n",
    "    contours = get_contours(image_line_removed)\n",
    "\n",
    "    return get_cropped_images(image_origin, contours)  # 글자로 추정되는 부분을 잘라낸 이미지들을 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_image(image, name_prefix='untitled'):\n",
    "    \"\"\" 이미지(OpenCV image 객체)를 이미지파일(.jpg)로 저장합니다.\n",
    "    :param image: 저장할 이미지 (OpenCV image 객체)\n",
    "    :param name_prefix: 파일명을 식별할 접두어 (확장자 제외)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # make file name with the datetime suffix.\n",
    "    d_date = datetime.datetime.now()  # get current datetime\n",
    "    current_datetime = d_date.strftime(\"%Y%m%d%I%M%S\")  # datetime to string\n",
    "    file_path = name_prefix + '_'+ current_datetime + \".jpg\"  # complete file name\n",
    "    cv2.imwrite(file_path, image)\n",
    "    \n",
    "def get_file_list(path):\n",
    "    \"\"\" path 가 가리키는 directory 의 모든 파일명을 읽어서 string 으로 반환합니다.\n",
    "    파일명은 Absolute path 가 포함된 이름입니다.\n",
    "\n",
    "    :param path: 읽어 들일 directory 의 절대경로\n",
    "    :return: directory 의 모든 file path 을 String 형으로 Array 에 담아 반환\n",
    "    \"\"\"\n",
    "    image_path_list = []\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        root_path = os.path.join(os.path.abspath(path), root)\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root_path, file)\n",
    "            image_path_list.append(file_path)\n",
    "\n",
    "    return image_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'** The NEW\\nWOXFORD\\n\\nEnglish-Chinese\\nDICTIONARY\\n\\n     \\n\\nFTX DMX in] th.\\n\\n*\\n* oo0%%\\nAeon Cio rae s e Tal\\nea 18 \"n\\n\\n   \\n  \\n\\n\\'L.§9I‘h§1§ﬂﬂﬁ&\\n\\nThe World\\'s Most Trusted'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_origin_text_from_file('C:/Users/Purple/textrecognition/chieng3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src import pre_process as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cropped_images = process_image('C:/Users/Purple/textrecognition/chieng3.png')\n",
    "count = 0\n",
    "for crop_image in cropped_images:\n",
    "    count += 1\n",
    "    save_image(crop_image, \"crop_\" + str(count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_text_from_image(image_path):\n",
    "    messages = []\n",
    "    path = 'C:/Users/Purple/textrecognition/recog'\n",
    "    for filename in get_file_list(path):\n",
    "        msg = get_text_from_file(filename)\n",
    "        messages.append(msg)\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'OXFORD',\n",
       " [],\n",
       " '',\n",
       " [],\n",
       " 'The NEW',\n",
       " \"'at o\",\n",
       " 'W soe me som ama\\n\\nB',\n",
       " \"* 收 词 释 义 355 000 余 条\\n\\n* 教 学 词 典 与 翻 译 词 典 之 全 新 结 合\\n。 语 言 知 识 与 百 科 信 息 之 最 佳 融 汇\\n\\n   \\n  \\n\\n\\\\ | A9 训\\n\\nn n i sme romo mesror aomen mas\\n\\nThe World's Most Trust\",\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '英 汉 双 解 大 词 典',\n",
       " [],\n",
       " '',\n",
       " 'English-Chinese\\nDICTIONARY']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_text_from_image('C:/Users/Purple/textrecognition/chieng3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13 .\\n, MMERRI\\nT-NAR#itR.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_text_from_file('C:/Users/Purple/textrecognition/mixed/engchi3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13 .\\n, MMERRI\\nT-NAR#itR.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_origin_text_from_file('C:/Users/Purple/textrecognition/mixed/engchi3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13 . #i\\n, MMERRI\\nT-NAR#itR.',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'T-ANAR#HR.',\n",
       " 'Plage Darvorto\\nMonaco',\n",
       " '13']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_text_from_image('C:/Users/Purple/textrecognition/mixed/engchi3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_text_from_image('C:/Users/Purple/textrecognition/mixed/engchi3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/Purple/textrecognition/config1.yml'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John 1:1-51\\nIn the beginning was the Word, and the Word was with God.,\\nand the Word was God.\\n2 He was in the beginning with God.\\n3 All things were made through him, and without him was\\nnot any thing made that was made.\\n4 In him was life,and the life was the light of men.\\n5 The light shines in the darkness, and the darkness has not\\novercome it.\\n14 And the Word became flesh and dwelt among us, and we\\nhave seen his glory, glory as of the only Son from the Father,\\nfull of grace and truth.\\nAlJbiG, OSNER, OMEN.\\n2\\n3 DUEMHINEMN: MEM, .\\n4 RTMRREAMY.\\n5 XHERE, ReNTNESX.\\n14 (EfERI4id, %% f6eser®.\\nRINtMHIEMEX,\\nThere are many more examples that I can bring up to show that\\n\\nthe Chinese do have this long memory in their written\\nlanguage, customs and philosophies.\\n\\n \\n\\nHow wonderful it is to know that the Chinese have all along\\nknown this One and Only God throughout their unbroken\\nhistory.\\n\\nThe Word of God revealed to us that we have sinned and fallen\\nshort of the glory of God. We have been separated from God\\nbecause of our sin.'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_text_from_image(image):\n",
    "    \"\"\" OCR 엔진(tesseract) 를 이용해 이미지에서 글자를 추출합니다.\n",
    "\n",
    "    :param image: 텍스트(Text)를 추출할 resource 이미지\n",
    "    :return: 추출한 텍스트(Text)를 String 형으로 반환\n",
    "    \"\"\"\n",
    "    # todo language 도 configs.yml file 에서 설정할 수 있도록 변경하기\n",
    "    img = Image.open(open(image,'rb'))\n",
    "    text = ocr.image_to_string(img, lang='eng+chi')\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
